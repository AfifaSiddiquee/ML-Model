# -*- coding: utf-8 -*-
"""new_app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j4b53ZVTxOFjcRkrpwWT-v39tQr9ip57
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

def load_and_preprocess_data(file_path):
    """Load dataset, split into train-test sets, and apply scaling."""
    data = pd.read_csv("/content/updated_diabetes.csv")
    X = data.drop(columns=['Outcome'])
    y = data['Outcome']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    return X_train_scaled, X_test_scaled, y_train, y_test, scaler

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    return X_train_scaled, X_test_scaled, y_train, y_test, scaler

import pickle
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler


def load_and_preprocess_data(file_path):
    """Load dataset, split into train-test sets, and apply scaling."""
    data = pd.read_csv(file_path)
    X = data.drop(columns=['Outcome'])
    y = data['Outcome']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    return X_train_scaled, X_test_scaled, y_train, y_test, scaler


def train_and_save_model(file_path, model_path="diabetes_model.pkl"):
    """Train a Logistic Regression model and save it along with the scaler."""
    X_train_scaled, X_test_scaled, y_train, y_test, scaler = load_and_preprocess_data(file_path)

    model = LogisticRegression(max_iter=1000)  # Increased max_iter to ensure convergence
    model.fit(X_train_scaled, y_train)

    predictions = model.predict(X_test_scaled)
    accuracy = accuracy_score(y_test, predictions)
    print(f"Model Accuracy: {accuracy * 100:.2f}%")

    # Save the trained model and scaler
    with open(model_path, "wb") as file:
        pickle.dump((scaler, model), file)

    return model_path, accuracy

if __name__ == "__main__":
    model_path, acc = train_and_save_model("updated_diabetes.csv")  # Use your updated CSV file path here
    print(f"Model saved at {model_path} with accuracy {acc * 100:.2f}%")

#import pandas as pd
#import matplotlib.pyplot as plt
#import seaborn as sns

# Load the dataset
#file_path = "/content/diabetes.csv"  # Update with your correct file path
#df = pd.read_csv(file_path)

# Count occurrences of each class
#class_counts = df['Outcome'].value_counts()
#print("Class Distribution:\n", class_counts)

# Plot class distribution
#sns.countplot(x=df['Outcome'])
#plt.title("Class Distribution")
#plt.show()

import pandas as pd

# Assuming `y_train` is your target variable after splitting the dataset
class_counts = y_train.value_counts()

# Check if the dataset contains more than one class
if len(class_counts) > 1:
    IR = class_counts.max() / class_counts.min()
    print(f"Imbalance Ratio (IR): {IR}")
else:
    print("The dataset has only one class.")

from imblearn.over_sampling import SMOTE
from collections import Counter  # Import Counter for class distribution
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler


def load_and_preprocess_data(file_path):
    """Load dataset, split into train-test sets, and apply scaling."""
    data = pd.read_csv(file_path)
    X = data.drop(columns=['Outcome'])
    y = data['Outcome']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    return X_train_scaled, X_test_scaled, y_train, y_test, scaler

# Call the function to create X_train, y_train etc.
file_path = "/content/diabetes.csv" #Make sure this path is correct.
X_train_scaled, X_test_scaled, y_train, y_test, scaler = load_and_preprocess_data(file_path)


# Apply SMOTE
smote = SMOTE(random_state=42)
X_smote, y_smote = smote.fit_resample(X_train_scaled, y_train) #Use X_train_scaled here since that is what your model will be trained on

# Print class distribution before and after SMOTE
print("Original class distribution:", Counter(y_train))
print("SMOTE class distribution:", Counter(y_smote))

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
df = pd.read_csv("diabetes.csv")

# Visualize the 'Pregnancies' column
plt.figure(figsize=(8, 6))
sns.boxplot(x=df['Pregnancies'])
plt.title('Boxplot for Pregnancies')
plt.show()

# Calculate the IQR for 'Pregnancies' column
Q1 = df['Pregnancies'].quantile(0.25)
Q3 = df['Pregnancies'].quantile(0.75)
IQR = Q3 - Q1

# Define outlier thresholds
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Detect outliers
outliers = df[(df['Pregnancies'] < lower_bound) | (df['Pregnancies'] > upper_bound)]

# Print out the number of outliers
print(f"Number of outliers in 'Pregnancies' column: {outliers.shape[0]}")

# Option 1: Remove outliers from the 'Pregnancies' column
#df_no_outliers = df[(df['Pregnancies'] >= lower_bound) & (df['Pregnancies'] <= upper_bound)]

# Option 2: Replace outliers with median (alternative to removing)
median_value = df['Pregnancies'].median()
df['Pregnancies'] = np.where(df['Pregnancies'] < lower_bound, median_value, df['Pregnancies'])
df['Pregnancies'] = np.where(df['Pregnancies'] > upper_bound, median_value, df['Pregnancies'])

# Visualize the result after removing or replacing outliers
plt.figure(figsize=(8, 6))
sns.boxplot(x=df['Pregnancies'])
plt.title('Boxplot for Pregnancies after Handling Outliers')
plt.show()

# Replace values in 'Pregnancies' column if the value is greater than 6 and convert to integer
df['Pregnancies'] = df['Pregnancies'].apply(lambda x: 6 if x > 6 else x).astype(int)

# Show the updated DataFrame
print(df.head())

import numpy as np
from sklearn.impute import SimpleImputer

# Replace 0.0 values in 'Insulin' column with NaN to treat them as missing values
df['Insulin'] = df['Insulin'].replace(0.0, np.nan)

# Initialize the imputer with the strategy 'median'
imputer = SimpleImputer(strategy='median')

# Apply the imputer to the 'Insulin' column and replace missing values with the median
df['Insulin'] = imputer.fit_transform(df[['Insulin']])

# Show the first few rows of the updated data
print(df)

# Check if there are any 0 values in each column
zero_check = (df == 0).sum()

# Display columns that have 0 values
print(zero_check[zero_check > 0])

# Replace 0 values with NaN first to treat them as missing
df[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'BMI']] = \
    df[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'BMI']].replace(0, np.nan)

# Use SimpleImputer to replace NaN with the median of each column
from sklearn.impute import SimpleImputer

# Initialize imputer with median strategy
imputer = SimpleImputer(strategy='median')

# Apply the imputer to the specified columns
df[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'BMI']] = \
    imputer.fit_transform(df[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'BMI']])

# Show the updated DataFrame
print(df.head())

# Check if there are any 0 values in each column
zero_check = (df == 0).sum()

# Display columns that have 0 values
print(zero_check[zero_check > 0])

# Ensure all preprocessing is applied to the dataset

# Save the updated DataFrame to a new CSV file (or overwrite the original one)
df.to_csv('updated_diabetes.csv', index=False)

# Optionally, check the first few rows of the updated dataset to verify
print(df.head())

import streamlit as st
import numpy as np
import pickle

# Load model and scaler
@st.cache_resource
def load_model(model_path="diabetes_model.pkl"):
    with open(model_path, "rb") as file:
        scaler, model = pickle.load(file)
    return scaler, model

st.title("Diabetes Wellness Evaluator")

scaler, model = load_model()

# User inputs
pregnancies = st.number_input("Pregnancies", 0, 20, 1)
glucose = st.number_input("Glucose Level", 0, 200, 100)
bp = st.number_input("Blood Pressure", 0, 150, 80)
skin_thickness = st.number_input("Skin Thickness", 0, 100, 20)
insulin = st.number_input("Insulin Level", 0, 900, 100)
bmi = st.number_input("BMI", 0.0, 50.0, 25.0)
dpf = st.number_input("Diabetes Pedigree Function", 0.0, 2.5, 0.5)
age = st.number_input("Age", 0, 100, 30)

if st.button("Predict"):
    input_data = np.array([[pregnancies, glucose, bp, skin_thickness, insulin, bmi, dpf, age]])
    input_scaled = scaler.transform(input_data)
    prediction = model.predict(input_scaled)

    if prediction[0] == 1:
        st.write("Diabetic")
        st.write("Based on your results, itâ€™s recommended to consult with your doctor for further guidance.")
    else:
        st.write("Not Diabetic")
        st.write("Great news! You're not showing signs of diabetes. Keep up the healthy lifestyle!")